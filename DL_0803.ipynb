{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 3])\n",
      "Epoch    0/1000 Cost: 1.098612\n",
      "Epoch  100/1000 Cost: 0.704199\n",
      "Epoch  200/1000 Cost: 0.622999\n",
      "Epoch  300/1000 Cost: 0.565717\n",
      "Epoch  400/1000 Cost: 0.515291\n",
      "Epoch  500/1000 Cost: 0.467662\n",
      "Epoch  600/1000 Cost: 0.421278\n",
      "Epoch  700/1000 Cost: 0.375402\n",
      "Epoch  800/1000 Cost: 0.329766\n",
      "Epoch  900/1000 Cost: 0.285073\n",
      "Epoch 1000/1000 Cost: 0.248155\n"
     ]
    }
   ],
   "source": [
    "# 다르게 표현하면 모든 클래스에 대해서 원-핫 인코딩을 통해 얻은 원-핫 벡터들은 모든 쌍에 대해서 유클리드 거리를 구해도 \n",
    "# 전부 유클리드 거리가 동일합니다. 원-핫 벡터는 이처럼 각 클래스의 표현 방법이 무작위성을 가진다는 점을 표현할 수 있습니다. \n",
    "# 뒤에서 다시 언급되겠지만 이러한 원-핫 벡터의 관계의 무작위성은 때로는 단어의 유사성을 구할 수 없다는 단점으로 언급되기도 합니다.\n",
    "# 결국 소프트맥스 회귀는 선택지의 개수만큼의 차원을 가지는 벡터를 만들고, 해당 벡터가 벡터의 모든 원소의 합이 1이 되도록 원소들의 값을 변환시키는 어떤 함수를 지나게 만들어야 합니다.\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "x_train = [[1, 2, 1, 1],\n",
    "           [2, 1, 3, 2],\n",
    "           [3, 1, 3, 4],\n",
    "           [4, 1, 5, 5],\n",
    "           [1, 7, 5, 5],\n",
    "           [1, 2, 5, 6],\n",
    "           [1, 6, 6, 6],\n",
    "           [1, 7, 7, 7]]# 텐서의 shape은 (8,4) 이다\n",
    "y_train = [2, 2, 2, 1, 1, 1, 0, 0]#텐서의 shape은 (,8) 이다\n",
    "x_train = torch.FloatTensor(x_train)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "# x_train의 크기는 8 × 4이며, y_train의 크기는 8 × 1입니다. 그런데 최종 사용할 레이블은 y_train에서 원-핫 인코딩을 한 결과이어야 합니다. \n",
    "# 클래스의 개수는 3개이므로 y_train에 원-핫 인코딩한 결과는 8 × 3의 개수를 가져야 합니다.\n",
    "# 여기서 1은 두 번째 차원 (index 1)을 기준으로 값을 할당한다는 의미입니다. \n",
    "# y_train.unsqueeze(1)는 새롭게 생성된 두 번째 차원에서 1을 할당할 위치를 나타냅니다.\n",
    "# 마지막으로, 1은 할당하고자 하는 값인 1을 나타냅니다.\n",
    "y_one_hot = torch.zeros(8, 3)\n",
    "y_one_hot.scatter_(1, y_train.unsqueeze(1), 1)\n",
    "print(y_one_hot.shape)\n",
    "\n",
    "# 모델 초기화\n",
    "W = torch.zeros((4, 3), requires_grad=True)\n",
    "b = torch.zeros((1, 3), requires_grad=True)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD([W, b], lr=0.1)\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # Cost 계산\n",
    "    z = x_train.matmul(W) + b\n",
    "    cost = F.cross_entropy(z, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 100번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    0/1000 Cost: 3.554311\n",
      "Epoch  100/1000 Cost: 0.640043\n",
      "Epoch  200/1000 Cost: 0.556386\n",
      "Epoch  300/1000 Cost: 0.501992\n",
      "Epoch  400/1000 Cost: 0.457725\n",
      "Epoch  500/1000 Cost: 0.418299\n",
      "Epoch  600/1000 Cost: 0.381315\n",
      "Epoch  700/1000 Cost: 0.345244\n",
      "Epoch  800/1000 Cost: 0.308956\n",
      "Epoch  900/1000 Cost: 0.272294\n",
      "Epoch 1000/1000 Cost: 0.243713\n"
     ]
    }
   ],
   "source": [
    "class SoftmaxClassifierModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear = nn.Linear(4,3)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "model = SoftmaxClassifierModel()\n",
    "#혹은 \n",
    "model = nn.Linear(4,3)\n",
    "# optimizer 설정\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "nb_epochs = 1000\n",
    "for epoch in range(nb_epochs + 1):\n",
    "\n",
    "    # H(x) 계산\n",
    "    prediction = model(x_train)\n",
    "\n",
    "    # cost 계산\n",
    "    cost = F.cross_entropy(prediction, y_train)\n",
    "\n",
    "    # cost로 H(x) 개선\n",
    "    optimizer.zero_grad()\n",
    "    cost.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    # 20번마다 로그 출력\n",
    "    if epoch % 100 == 0:\n",
    "        print('Epoch {:4d}/{} Cost: {:.6f}'.format(\n",
    "            epoch, nb_epochs, cost.item()\n",
    "        ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "다음 기기로 학습합니다: cpu\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:02<00:00, 4107426.43it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 28979831.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\train-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 3003610.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-images-idx3-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 4553185.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/MNIST\\raw\\t10k-labels-idx1-ubyte.gz to MNIST_data/MNIST\\raw\n",
      "\n",
      "Epoch: 0001 cost = 0.535150588\n",
      "Epoch: 0002 cost = 0.359577745\n",
      "Epoch: 0003 cost = 0.331264287\n",
      "Epoch: 0004 cost = 0.316404700\n",
      "Epoch: 0005 cost = 0.307106972\n",
      "Epoch: 0006 cost = 0.300456554\n",
      "Epoch: 0007 cost = 0.294933408\n",
      "Epoch: 0008 cost = 0.290956199\n",
      "Epoch: 0009 cost = 0.287074089\n",
      "Epoch: 0010 cost = 0.284515619\n",
      "Epoch: 0011 cost = 0.281914055\n",
      "Epoch: 0012 cost = 0.279526860\n",
      "Epoch: 0013 cost = 0.277636588\n",
      "Epoch: 0014 cost = 0.275874794\n",
      "Epoch: 0015 cost = 0.274422705\n",
      "Learning finished\n"
     ]
    }
   ],
   "source": [
    "#mnist 데이터 분류하기\n",
    "import torch\n",
    "import torchvision.datasets as dsets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "\n",
    "USE_CUDA = torch.cuda.is_available() # GPU를 사용가능하면 True, 아니라면 False를 리턴\n",
    "device = torch.device(\"cuda\" if USE_CUDA else \"cpu\") # GPU 사용 가능하면 사용하고 아니면 CPU 사용\n",
    "print(\"다음 기기로 학습합니다:\", device)\n",
    "\n",
    "# for reproducibility\n",
    "random.seed(777)\n",
    "torch.manual_seed(777)\n",
    "if device == 'cuda':\n",
    "    torch.cuda.manual_seed_all(777)\n",
    "\n",
    "# hyperparameters\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "# MNIST dataset\n",
    "mnist_train = dsets.MNIST(root='MNIST_data/',\n",
    "                          train=True,\n",
    "                          transform=transforms.ToTensor(),\n",
    "                          download=True)\n",
    "\n",
    "mnist_test = dsets.MNIST(root='MNIST_data/',\n",
    "                         train=False,\n",
    "                         transform=transforms.ToTensor(),\n",
    "                         download=True)\n",
    "# dataset loader\n",
    "data_loader = DataLoader(dataset=mnist_train,batch_size=batch_size,shuffle=True,drop_last=True)\n",
    "#drop_last를 하는 이유를 이해하기 위해서 1,000개의 데이터가 있다고 했을 때, 배치 크기가 128이라고 해봅시다.\n",
    "#1,000을 128로 나누면 총 7개가 나오고 나머지로 104개가 남습니다. 이때 104개를 마지막 배치로 한다고 하였을 때\n",
    "#128개를 충족하지 못하였으므로 104개를 그냥 버릴 수도 있습니다. 이때 마지막 배치를 버리려면 drop_last=True를 해주면 됩니다.\n",
    "#이는 다른 미니 배치보다 개수가 적은 마지막 배치를 경사 하강법에 사용하여 마지막 배치가 상대적으로 과대 평가되는 현상을 막아줍니다.\n",
    "\n",
    "# MNIST data image of shape 28 * 28 = 784\n",
    "linear = nn.Linear(784, 10, bias=True).to(device)\n",
    "# 비용 함수와 옵티마이저 정의\n",
    "criterion = nn.CrossEntropyLoss().to(device) # 내부적으로 소프트맥스 함수를 포함하고 있음.\n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(training_epochs): # 앞서 training_epochs의 값은 15로 지정함.\n",
    "    avg_cost = 0\n",
    "    total_batch = len(data_loader)\n",
    "\n",
    "    for X, Y in data_loader:\n",
    "        # 배치 크기가 100이므로 아래의 연산에서 X는 (100, 784)의 텐서가 된다.\n",
    "        X = X.view(-1, 28 * 28).to(device)\n",
    "        # 레이블은 원-핫 인코딩이 된 상태가 아니라 0 ~ 9의 정수.\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = linear(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_batch\n",
    "\n",
    "    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n",
    "\n",
    "print('Learning finished')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8883000016212463\n",
      "Label:  2\n",
      "Prediction:  8\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 테스트 데이터를 사용하여 모델을 테스트한다.\n",
    "with torch.no_grad(): # torch.no_grad()를 하면 gradient 계산을 수행하지 않는다.\n",
    "    X_test = mnist_test.test_data.view(-1, 28 * 28).float().to(device)\n",
    "    Y_test = mnist_test.test_labels.to(device)\n",
    "\n",
    "    prediction = linear(X_test)\n",
    "    correct_prediction = torch.argmax(prediction, 1) == Y_test\n",
    "    accuracy = correct_prediction.float().mean()\n",
    "    print('Accuracy:', accuracy.item())\n",
    "\n",
    "    # MNIST 테스트 데이터에서 무작위로 하나를 뽑아서 예측을 해본다\n",
    "    r = random.randint(0, len(mnist_test) - 1)\n",
    "    X_single_data = mnist_test.test_data[r:r + 1].view(-1, 28 * 28).float().to(device)\n",
    "    Y_single_data = mnist_test.test_labels[r:r + 1].to(device)\n",
    "\n",
    "    print('Label: ', Y_single_data.item())\n",
    "    single_prediction = linear(X_single_data)\n",
    "    print('Prediction: ', torch.argmax(single_prediction, 1).item())\n",
    "\n",
    "    plt.imshow(mnist_test.test_data[r:r + 1].view(28, 28), cmap='Greys', interpolation='nearest')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.],\n",
      "        [ 9., 12.]])\n",
      "torch.Size([2, 2])\n",
      "cpu\n",
      "torch.float32\n",
      "tensor([11., 16.])\n",
      "tensor([ 6., 21.])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([0, 1, 2, 3])\n",
      "tensor([0.1749, 0.7438, 0.2233])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.FloatTensor([[1,2],[3,4]])\n",
    "b = torch.FloatTensor([[2,2],[3,3]])\n",
    "a.mul_(b)\n",
    "print(a)\n",
    "print(a.shape)\n",
    "print(a.device)\n",
    "print(a.dtype)\n",
    "print(a.sum(dim=0))\n",
    "print(a.sum(dim=-1))\n",
    "t1 = torch.zeros(2,3)\n",
    "print(t1)\n",
    "t2 = torch.arange(4)\n",
    "print(t2)\n",
    "t3 = torch.rand(3)\n",
    "print(t3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "t1_gpu = t1.to(device)\n",
    "print(t1_gpu.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0, 1],\n",
      "        [2, 3],\n",
      "        [4, 5]])\n",
      "tensor([[[0, 1, 2]],\n",
      "\n",
      "        [[3, 4, 5]]])\n",
      "tensor([[0, 2, 4],\n",
      "        [1, 3, 5]])\n"
     ]
    }
   ],
   "source": [
    "t2 = torch.arange(6)\n",
    "t2_reshape = t2.reshape(3,2)\n",
    "print(t2_reshape)\n",
    "t2_squeeze = t2.reshape(2,1,3)\n",
    "print(t2_squeeze)\n",
    "t2_permute = t2_reshape.permute(1,0)\n",
    "print(t2_permute)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 3]) torch.Size([3, 4])\n",
      "tensor([[  5.,  14.,  23.,  32.],\n",
      "        [ 14.,  50.,  86., 122.]]) torch.Size([2, 4])\n"
     ]
    }
   ],
   "source": [
    "t1 = torch.FloatTensor([[0,1,2],[3,4,5]])\n",
    "t2 = torch.FloatTensor([[0,1,2],[3,4,5],[6,7,8],[9,10,11]])\n",
    "\n",
    "t2 = t2.transpose(0,1)\n",
    "print(t1.shape, t2.shape)\n",
    "\n",
    "t33 = t1 @ t2\n",
    "print(t3,t3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1, 1, 1, 1])\n",
      "tensor([3, 3])\n"
     ]
    }
   ],
   "source": [
    "row_argmax = torch.argmax(t33,dim=0)\n",
    "print(row_argmax)\n",
    "col_argmax = torch.argmax(t33,dim=-1)\n",
    "print(col_argmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0., 1., 2.],\n",
      "         [3., 4., 5.]],\n",
      "\n",
      "        [[0., 1., 2.],\n",
      "         [3., 4., 5.]]]) \n",
      " tensor([[[0., 0.],\n",
      "         [1., 1.],\n",
      "         [2., 2.]],\n",
      "\n",
      "        [[3., 3.],\n",
      "         [4., 4.],\n",
      "         [5., 5.]]])\n",
      "tensor([[0., 1., 2.],\n",
      "        [3., 4., 5.],\n",
      "        [0., 1., 2.],\n",
      "        [3., 4., 5.]])\n"
     ]
    }
   ],
   "source": [
    "t11 = torch.stack([t1,t1],dim=0)\n",
    "t112 = torch.stack([t1,t1],dim=-1)\n",
    "t111 = torch.cat([t1,t1],dim=0)\n",
    "\n",
    "print(t11,\"\\n\",t112)\n",
    "print(t111)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637],\n",
      "        [ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637]])\n",
      "tensor([ 0.0000,  0.0000, -0.1367,  0.9866,  0.0637])\n",
      "tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "        [9.9751e-01, 9.3588e-01, 5.4297e-06],\n",
      "        [9.9854e-01, 9.3685e-01, 5.4353e-06],\n",
      "        [1.3688e+00, 1.2842e+00, 7.4505e-06]])\n",
      "tensor([3.2926e-01, 3.0892e-01, 1.7923e-06])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn.functional as F\n",
    "\n",
    "x = torch.ones(7)\n",
    "y = torch.zeros(3)\n",
    "\n",
    "w1 = torch.randn(7,5,requires_grad=True)\n",
    "b1 = torch.randn(5,requires_grad=True)\n",
    "w2 = torch.randn(5,3,requires_grad=True)\n",
    "b2 = torch.randn(3,requires_grad=True)\n",
    "\n",
    "z1 = x@w1+b1\n",
    "z2 = F.relu(z1)\n",
    "z3 = z2@w2+b2\n",
    "#calcylate loss\n",
    "loss = F.binary_cross_entropy_with_logits(z3,y)\n",
    "#backpropagation\n",
    "loss.backward()\n",
    "print(w1.grad)\n",
    "print(b1.grad)\n",
    "print(w2.grad)\n",
    "print(b2.grad)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected str, bytes or os.PathLike object, not NoneType",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\hyok1\\OneDrive\\바탕 화면\\GitHub\\AI_Study\\DL_0729.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 26>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m             batch\u001b[39m.\u001b[39mappend(x_padded)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39mstack(batch, dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m dataset \u001b[39m=\u001b[39m SimpleDataset()\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m dataLoader \u001b[39m=\u001b[39m DataLoader(dataset,batch_size\u001b[39m=\u001b[39m\u001b[39m16\u001b[39m,collate_fn\u001b[39m=\u001b[39mmy_collate_fn,shuffle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n",
      "\u001b[1;32mc:\\Users\\hyok1\\OneDrive\\바탕 화면\\GitHub\\AI_Study\\DL_0729.ipynb Cell 8\u001b[0m in \u001b[0;36mSimpleDataset.__init__\u001b[1;34m(self, csv_file, root_dir)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m,csv_file \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,root_dir\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\u001b[39m#가져오는 파일에 따라 다르게 설정\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mopen\u001b[39;49m(csv_file) \u001b[39mas\u001b[39;00m file:\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mannotations \u001b[39m=\u001b[39m file\u001b[39m.\u001b[39mreadlines()\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/hyok1/OneDrive/%EB%B0%94%ED%83%95%20%ED%99%94%EB%A9%B4/GitHub/AI_Study/DL_0729.ipynb#X11sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mroot_dir \u001b[39m=\u001b[39m root_dir\n",
      "\u001b[1;31mTypeError\u001b[0m: expected str, bytes or os.PathLike object, not NoneType"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import csv\n",
    "\n",
    "class SimpleDataset(Dataset):\n",
    "    def __init__(self,csv_file = None,root_dir=None):#가져오는 파일에 따라 다르게 설정\n",
    "        with open(csv_file) as file:\n",
    "            self.annotations = file.readlines()\n",
    "        self.root_dir = root_dir\n",
    "    def __getitem__(self,idx):\n",
    "        x_path,y = self.annotations[idx]\n",
    "        x = self.read(x_path)\n",
    "        return x,y\n",
    "    def __len__(self):\n",
    "        return len(self.annotations)\n",
    "    def read(self,x_path):\n",
    "        return x_path\n",
    "    \n",
    "def my_collate_fn(data):#각기 다른 배치사이즈로 샘플을 만들고 나서 빈칸을 0으로 패딩해주는 과정\n",
    "        max_len =10\n",
    "        batch = []\n",
    "        for x,y in data:\n",
    "            x_padded = torch.cat([x,torch.zeros(max_len-x.shape[0])])\n",
    "            batch.append(x_padded)\n",
    "        return torch.stack(batch, dim=0)\n",
    "   \n",
    "dataset = SimpleDataset()\n",
    "dataLoader = DataLoader(dataset,batch_size=16,collate_fn=my_collate_fn,shuffle=True)\n",
    "#수정필요함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, scheduler, optim, loss_fn, train_loader, epochs, device):\n",
    "    for epoch in range(epochs):\n",
    "        train_loss = 0.0\n",
    "        model.train()\n",
    "        for batch in train_loader:\n",
    "            optim.zero_grad()\n",
    "            input, target = batch_size\n",
    "            input = input.to(device)\n",
    "            target = target.to(device)\n",
    "            output = model(input)\n",
    "            loss = loss_fn(output,target)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss += loss.detach().item()\n",
    "        scheduler.step()\n",
    "        train_loss /= len(train_loader.dataset)\n",
    "        print(f\"Epoch: {epoch+1},Trainning Loss : {train_loss}\")\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "optimizer = optim.SGD(model.parameters(),lr=1e-2,momentum=0.9)\n",
    "scheduler = optim.lr_scheduler.ExponentialLR(optimizer,gmma=0.9)\n",
    "model.to(device)\n",
    "\n",
    "train(model, scheduler, optim, nn.CrossEntropyLoss(), train_loader, num_epochs, device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
